2022-10-07 02:33:21.987  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 02:33:25.288  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 02:33:38.983  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 02:33:38.986  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 02:33:39.003  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 02:33:41.197  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 02:33:41.716  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 504 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 02:33:42.522  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 02:33:42.790  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:33:42.795  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:33:42.799  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:33:46.119  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@173a5fad, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@2ce47652], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@65d90b7f]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@2a42019a], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 02:33:46.425  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:33:47.052  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:33:49.282  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:105}] to localhost:27017
2022-10-07 02:33:49.282  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:106}] to localhost:27017
2022-10-07 02:33:49.285  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=129444200}
2022-10-07 02:33:53.582  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 02:33:56.103  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 02:33:56.300  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 02:33:56.486  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 02:33:56.601  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 02:33:56.614  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 02:33:56.732  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 02:33:56.733  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 02:33:56.733  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 02:33:56.733  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 02:33:56.734  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 02:33:56.734  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 02:33:56.734  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 02:33:57.555  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 02:33:57.562  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 02:33:57.567  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 02:33:57.578  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665128037575 with initial instances count: 5
2022-10-07 02:33:57.580  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 02:33:57.580  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665128037580, current=UP, previous=STARTING]
2022-10-07 02:33:57.585  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 02:33:57.668  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 02:33:57.705  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 02:33:57.945  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 02:33:57.945  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 02:33:57.949  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 02:33:57.950  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 02:33:57.950  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665128037946
2022-10-07 02:33:57.958  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 02:33:58.126  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 02:33:58.129  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 02:33:58.983  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 02:33:58.989  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 02:33:58.991  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:33:58.996  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:33:59.026  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 02:33:59.027  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:33:59.411  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=29, memberId='consumer-group_json-1-9135c3af-efbb-4835-8aba-26c150166ee6', protocol='range'}
2022-10-07 02:33:59.766  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=29, memberId='consumer-group_json-1-9135c3af-efbb-4835-8aba-26c150166ee6', protocol='range'}
2022-10-07 02:33:59.778  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 02:33:59.785  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 02:33:59.813  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 02:33:59.816  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 02:34:01.914  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 43.31 seconds (JVM running for 46.887)
2022-10-07 02:34:38.359  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application OPERATION-SERVICES with eureka with status DOWN
2022-10-07 02:34:38.361  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665128078361, current=DOWN, previous=UP]
2022-10-07 02:34:38.362  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 02:34:38.377  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 02:34:38.390  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Revoke previously assigned partitions Kafka_target-0
2022-10-07 02:34:38.391  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 02:34:38.393  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Member consumer-group_json-1-9135c3af-efbb-4835-8aba-26c150166ee6 sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2022-10-07 02:34:38.396  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 02:34:38.396  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 02:34:38.396  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Unsubscribed all topics or patterns and assigned partitions
2022-10-07 02:34:38.398  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 02:34:38.398  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 02:34:38.444  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics scheduler closed
2022-10-07 02:34:38.445  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-10-07 02:34:38.446  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics reporters closed
2022-10-07 02:34:38.457  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.u.AppInfoParser                  : App info kafka.consumer for consumer-group_json-1 unregistered
2022-10-07 02:34:38.459  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: Consumer stopped
2022-10-07 02:34:42.698  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Shutting down DiscoveryClient ...
2022-10-07 02:34:45.715  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Unregistering ...
2022-10-07 02:34:45.765  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - deregister  status: 200
2022-10-07 02:34:45.773  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Completed shut down of DiscoveryClient
2022-10-07 02:43:51.823  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 02:43:54.879  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 02:44:08.551  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 02:44:08.554  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 02:44:08.570  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 02:44:10.870  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 02:44:11.295  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 411 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 02:44:12.110  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 02:44:12.371  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:44:12.375  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:44:12.378  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:44:15.273  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@65d90b7f, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@2a42019a], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@6fc0e448]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@60194904], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 02:44:15.584  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:44:16.071  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:44:18.638  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:108}] to localhost:27017
2022-10-07 02:44:18.638  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:107}] to localhost:27017
2022-10-07 02:44:18.640  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=146213000}
2022-10-07 02:44:22.679  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 02:44:25.291  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 02:44:25.472  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 02:44:25.644  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 02:44:25.792  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 02:44:25.804  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 02:44:25.857  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 02:44:25.857  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 02:44:25.858  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 02:44:25.858  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 02:44:25.858  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 02:44:25.858  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 02:44:25.859  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 02:44:26.568  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 02:44:26.574  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 02:44:26.581  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 02:44:26.594  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665128666591 with initial instances count: 4
2022-10-07 02:44:26.596  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 02:44:26.598  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665128666598, current=UP, previous=STARTING]
2022-10-07 02:44:26.603  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 02:44:26.707  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 02:44:26.738  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 02:44:26.966  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 02:44:26.966  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 02:44:26.970  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 02:44:26.971  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 02:44:26.971  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665128666966
2022-10-07 02:44:26.978  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 02:44:27.115  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 02:44:27.117  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 02:44:28.004  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 02:44:28.011  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 02:44:28.014  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:44:28.020  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:44:28.051  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 02:44:28.052  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:44:28.283  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=31, memberId='consumer-group_json-1-ec5d1f29-a87a-48df-8634-333accc92d3c', protocol='range'}
2022-10-07 02:44:28.574  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=31, memberId='consumer-group_json-1-ec5d1f29-a87a-48df-8634-333accc92d3c', protocol='range'}
2022-10-07 02:44:28.583  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 02:44:28.588  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 02:44:28.611  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 02:44:28.725  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 02:44:30.720  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 41.981 seconds (JVM running for 44.804)
2022-10-07 02:45:26.404  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] o.m.d.connection                         : Opened connection [connectionId{localValue:3, serverValue:109}] to localhost:27017
2022-10-07 02:48:19.199  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-10-07 02:48:19.200  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Requesting disconnect from last known coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:48:27.870  INFO LAPTOP-LTI5PG0G --- [tbeatExecutor-0] o.a.h.i.e.RetryExec                      : I/O exception (java.net.SocketException) caught when processing request to {}->http://localhost:8761: Software caused connection abort: socket write error
2022-10-07 02:48:27.871  INFO LAPTOP-LTI5PG0G --- [tbeatExecutor-0] o.a.h.i.e.RetryExec                      : Retrying request to {}->http://localhost:8761
2022-10-07 02:48:27.871  INFO LAPTOP-LTI5PG0G --- [freshExecutor-0] o.a.h.i.e.RetryExec                      : I/O exception (java.net.SocketException) caught when processing request to {}->http://localhost:8761: Software caused connection abort: socket write error
2022-10-07 02:48:29.309  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Client requested disconnect from node 2147483647
2022-10-07 02:48:19.198  WARN LAPTOP-LTI5PG0G --- [scoveryClient-0] c.n.d.TimedSupervisorTask                : task supervisor timed out
java.util.concurrent.TimeoutException
	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
	at com.netflix.discovery.TimedSupervisorTask.run(TimedSupervisorTask.java:68)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 02:48:19.199  WARN LAPTOP-LTI5PG0G --- [scoveryClient-1] c.n.d.TimedSupervisorTask                : task supervisor timed out
java.util.concurrent.TimeoutException
	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
	at com.netflix.discovery.TimedSupervisorTask.run(TimedSupervisorTask.java:68)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 02:48:29.307  INFO LAPTOP-LTI5PG0G --- [freshExecutor-0] o.a.h.i.e.RetryExec                      : Retrying request to {}->http://localhost:8761
2022-10-07 02:48:30.871  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:48:30.873  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-10-07 02:48:30.876  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:48:30.887  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Attempt to heartbeat with Generation{generationId=31, memberId='consumer-group_json-1-ec5d1f29-a87a-48df-8634-333accc92d3c', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-10-07 02:48:30.888  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-10-07 02:48:30.888  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-10-07 02:48:30.889  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-10-07 02:48:30.890  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Lost previously assigned partitions Kafka_target-0
2022-10-07 02:48:30.891  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions lost: [Kafka_target-0]
2022-10-07 02:48:30.892  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 02:48:30.893  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:48:30.898  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 02:48:30.899  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:48:33.986  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=33, memberId='consumer-group_json-1-73f119e9-a0c8-4662-b102-b7fc7979dbea', protocol='range'}
2022-10-07 02:48:41.154  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=33, memberId='consumer-group_json-1-73f119e9-a0c8-4662-b102-b7fc7979dbea', protocol='range'}
2022-10-07 02:48:41.155  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 02:48:41.156  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 02:48:41.164  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 02:48:41.165  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 02:50:00.581  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-10-07 02:50:00.582  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Requesting disconnect from last known coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:50:00.585  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Client requested disconnect from node 2147483647
2022-10-07 02:50:00.581  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 02:50:00.604  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:50:00.609  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-10-07 02:50:00.616  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:50:00.619  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
2022-10-07 02:50:00.620  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Requesting disconnect from last known coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:53:11.389  INFO LAPTOP-LTI5PG0G --- [freshExecutor-0] o.a.h.i.e.RetryExec                      : I/O exception (java.net.SocketException) caught when processing request to {}->http://localhost:8761: Software caused connection abort: recv failed
2022-10-07 02:53:11.390  INFO LAPTOP-LTI5PG0G --- [freshExecutor-0] o.a.h.i.e.RetryExec                      : Retrying request to {}->http://localhost:8761
2022-10-07 02:53:11.391  WARN LAPTOP-LTI5PG0G --- [scoveryClient-1] c.n.d.TimedSupervisorTask                : task supervisor timed out
java.util.concurrent.TimeoutException
	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
	at com.netflix.discovery.TimedSupervisorTask.run(TimedSupervisorTask.java:68)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 02:53:11.407  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:53:11.407  WARN LAPTOP-LTI5PG0G --- [scoveryClient-0] c.n.d.TimedSupervisorTask                : task supervisor timed out
java.util.concurrent.TimeoutException
	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
	at com.netflix.discovery.TimedSupervisorTask.run(TimedSupervisorTask.java:68)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 02:53:11.444  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Attempt to heartbeat with Generation{generationId=33, memberId='consumer-group_json-1-73f119e9-a0c8-4662-b102-b7fc7979dbea', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-10-07 02:53:11.445  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-10-07 02:53:11.445  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-10-07 02:53:11.448  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-10-07 02:53:11.449  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Lost previously assigned partitions Kafka_target-0
2022-10-07 02:53:11.449  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions lost: [Kafka_target-0]
2022-10-07 02:53:11.449  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 02:53:11.450  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:53:11.458  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 02:53:11.459  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:53:11.655  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=35, memberId='consumer-group_json-1-2ab8dc6b-7e83-4ce1-bc48-d9e052cca9ae', protocol='range'}
2022-10-07 02:53:11.864  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=35, memberId='consumer-group_json-1-2ab8dc6b-7e83-4ce1-bc48-d9e052cca9ae', protocol='range'}
2022-10-07 02:53:11.868  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 02:53:11.868  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 02:53:11.878  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 02:53:11.879  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 02:53:28.402  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Node -1 disconnected.
2022-10-07 02:55:00.609  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 03:07:54.925  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Node 2147483647 disconnected.
2022-10-07 03:07:54.928  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Disconnecting from node 0 due to request timeout.
2022-10-07 03:07:54.929  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cancelled in-flight FETCH request with correlation id 930 due to node 0 being disconnected (elapsed time since creation: 550923ms, elapsed time since send: 550922ms, request timeout: 30000ms)
2022-10-07 03:07:54.930  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.FetchSessionHandler              : [Consumer clientId=consumer-group_json-1, groupId=group_json] Error sending fetch request (sessionId=413452142, epoch=765) to node 0:
org.apache.kafka.common.errors.DisconnectException
2022-10-07 03:07:54.931  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-10-07 03:07:55.170  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 03:07:55.228  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: group is already rebalancing
2022-10-07 03:07:55.231  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Revoke previously assigned partitions Kafka_target-0
2022-10-07 03:07:55.232  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 03:07:55.232  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 03:07:55.271  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=36, memberId='consumer-group_json-1-2ab8dc6b-7e83-4ce1-bc48-d9e052cca9ae', protocol='range'}
2022-10-07 03:07:55.699  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=36, memberId='consumer-group_json-1-2ab8dc6b-7e83-4ce1-bc48-d9e052cca9ae', protocol='range'}
2022-10-07 03:07:55.701  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 03:07:55.702  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 03:07:55.713  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 03:07:55.714  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 03:09:11.372  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 03:14:11.377  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 03:19:11.382  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 03:24:11.386  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 03:29:11.400  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 03:34:11.401  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 03:39:11.405  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 03:44:11.415  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 03:49:11.418  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 03:54:11.432  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 03:59:11.441  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 04:04:11.456  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 04:09:11.461  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 04:14:11.475  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 04:19:11.487  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 04:24:11.495  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 04:29:11.501  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 04:34:11.504  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 04:39:11.508  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 04:44:11.519  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 04:49:11.531  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 04:54:11.534  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 04:59:11.546  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 05:04:11.554  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 05:09:11.556  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 05:14:11.558  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 05:19:11.559  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 05:24:11.572  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 05:29:11.578  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 05:34:11.580  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 05:39:11.589  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 05:44:11.600  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 05:49:11.603  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 05:54:11.606  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 05:59:11.607  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 06:04:11.618  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 06:09:11.624  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 06:14:11.632  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 06:19:11.647  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 06:24:11.662  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 06:29:11.669  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 06:34:11.676  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 06:39:11.685  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 06:44:11.687  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 06:47:20.008  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Disconnecting from node 0 due to request timeout.
2022-10-07 06:47:20.009  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cancelled in-flight FETCH request with correlation id 31022 due to node 0 being disconnected (elapsed time since creation: 40253ms, elapsed time since send: 40253ms, request timeout: 30000ms)
2022-10-07 06:47:20.010  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.FetchSessionHandler              : [Consumer clientId=consumer-group_json-1, groupId=group_json] Error sending fetch request (sessionId=722203393, epoch=25676) to node 0:
org.apache.kafka.common.errors.DisconnectException
2022-10-07 06:47:20.019  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Exception in monitor thread while connecting to server localhost:27017
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.exceptionCaught(NettyStream.java:427)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:302)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:281)
	at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:273)
	at com.mongodb.connection.netty.NettyStream$ReadTimeoutTask.run(NettyStream.java:564)
	at io.netty.util.concurrent.PromiseTask.runTask(PromiseTask.java:98)
	at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:153)
	at io.netty.util.concurrent.AbstractEventExecutor.runTask$$$capture(AbstractEventExecutor.java:174)
	at io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute$$$capture(AbstractEventExecutor.java:167)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: io.netty.handler.timeout.ReadTimeoutException
2022-10-07 06:47:20.040  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:4, serverValue:111}] to localhost:27017
2022-10-07 06:47:20.041  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=9619400}
2022-10-07 06:49:51.729  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 06:52:16.028  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application OPERATION-SERVICES with eureka with status DOWN
2022-10-07 06:52:16.029  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665143536029, current=DOWN, previous=UP]
2022-10-07 06:52:16.030  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 06:52:16.052  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Revoke previously assigned partitions Kafka_target-0
2022-10-07 06:52:16.053  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 06:52:16.053  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Member consumer-group_json-1-2ab8dc6b-7e83-4ce1-bc48-d9e052cca9ae sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2022-10-07 06:52:16.055  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 06:52:16.057  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 06:52:16.060  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Unsubscribed all topics or patterns and assigned partitions
2022-10-07 06:52:16.062  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 06:52:16.063  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 06:52:16.063  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 06:52:16.070  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics scheduler closed
2022-10-07 06:52:16.070  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-10-07 06:52:16.071  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics reporters closed
2022-10-07 06:52:16.077  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.u.AppInfoParser                  : App info kafka.consumer for consumer-group_json-1 unregistered
2022-10-07 06:52:16.079  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: Consumer stopped
2022-10-07 06:52:16.112  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] o.m.d.connection                         : Opened connection [connectionId{localValue:5, serverValue:114}] to localhost:27017
2022-10-07 06:52:20.319  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Shutting down DiscoveryClient ...
2022-10-07 06:52:23.336  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Unregistering ...
2022-10-07 06:52:23.362  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - deregister  status: 200
2022-10-07 06:52:23.369  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Completed shut down of DiscoveryClient
2022-10-07 06:53:03.678  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 06:53:05.649  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 06:53:09.453  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 06:53:09.456  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 06:53:09.469  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 06:53:11.337  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 06:53:11.678  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 331 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 06:53:12.340  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 06:53:12.558  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 06:53:12.561  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 06:53:12.566  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 06:53:15.081  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@42d174ad, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@4ec0229c], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@173a5fad]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@2ce47652], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 06:53:15.355  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 06:53:15.831  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 06:53:17.458  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:116}] to localhost:27017
2022-10-07 06:53:17.458  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:115}] to localhost:27017
2022-10-07 06:53:17.459  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=126067900}
2022-10-07 06:53:20.557  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 06:53:22.366  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 06:53:22.513  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 06:53:22.651  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 06:53:22.788  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 06:53:22.800  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 06:53:22.851  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 06:53:22.852  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 06:53:22.852  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 06:53:22.852  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 06:53:22.852  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 06:53:22.852  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 06:53:22.853  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 06:53:23.395  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 06:53:23.399  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 06:53:23.404  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 06:53:23.411  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665143603409 with initial instances count: 4
2022-10-07 06:53:23.412  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 06:53:23.413  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665143603413, current=UP, previous=STARTING]
2022-10-07 06:53:23.417  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 06:53:23.482  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 06:53:23.563  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 06:53:23.786  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 06:53:23.786  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 06:53:23.790  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 06:53:23.790  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 06:53:23.790  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665143603786
2022-10-07 06:53:23.797  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 06:53:23.947  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 06:53:23.949  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 06:53:24.668  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 06:53:24.673  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 06:53:24.675  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 06:53:24.678  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 06:53:24.702  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 06:53:24.702  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 06:53:26.243  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 24.478 seconds (JVM running for 28.687)
2022-10-07 06:53:26.970  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=38, memberId='consumer-group_json-1-ed867c1e-af05-4449-ba0e-c14c338fdee6', protocol='range'}
2022-10-07 06:53:27.220  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=38, memberId='consumer-group_json-1-ed867c1e-af05-4449-ba0e-c14c338fdee6', protocol='range'}
2022-10-07 06:53:27.228  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 06:53:27.234  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 06:53:27.255  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 06:53:27.257  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 06:54:36.205  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] o.m.d.connection                         : Opened connection [connectionId{localValue:3, serverValue:117}] to localhost:27017
2022-10-07 06:58:22.861  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 07:02:25.097  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Node -1 disconnected.
2022-10-07 07:03:22.875  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 07:08:22.880  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 07:13:22.885  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 07:16:57.011  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application OPERATION-SERVICES with eureka with status DOWN
2022-10-07 07:16:57.012  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665145017012, current=DOWN, previous=UP]
2022-10-07 07:16:57.013  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 07:16:57.031  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Revoke previously assigned partitions Kafka_target-0
2022-10-07 07:16:57.033  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 07:16:57.034  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Member consumer-group_json-1-ed867c1e-af05-4449-ba0e-c14c338fdee6 sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2022-10-07 07:16:57.036  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 07:16:57.037  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 07:16:57.037  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Unsubscribed all topics or patterns and assigned partitions
2022-10-07 07:16:57.038  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 07:16:57.038  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 07:16:57.038  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 07:16:57.044  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics scheduler closed
2022-10-07 07:16:57.045  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-10-07 07:16:57.045  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics reporters closed
2022-10-07 07:16:57.051  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.u.AppInfoParser                  : App info kafka.consumer for consumer-group_json-1 unregistered
2022-10-07 07:16:57.053  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: Consumer stopped
2022-10-07 07:17:01.297  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Shutting down DiscoveryClient ...
2022-10-07 07:17:04.305  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Unregistering ...
2022-10-07 07:17:04.310  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - deregister  status: 200
2022-10-07 07:17:04.319  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Completed shut down of DiscoveryClient
2022-10-07 07:17:19.650  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 07:17:21.954  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 07:17:25.911  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 07:17:25.914  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 07:17:25.927  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 07:17:27.792  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 07:17:28.085  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 283 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 07:17:28.766  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 07:17:28.964  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:17:28.967  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:17:28.972  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:17:31.381  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@2ce47652, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@65d90b7f], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@2a42019a]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@6fc0e448], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 07:17:31.643  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 07:17:32.092  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 07:17:33.807  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:121}] to localhost:27017
2022-10-07 07:17:33.807  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:122}] to localhost:27017
2022-10-07 07:17:33.810  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=135250000}
2022-10-07 07:17:36.646  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 07:17:38.361  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 07:17:38.522  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 07:17:38.664  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 07:17:38.773  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 07:17:38.785  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 07:17:38.829  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 07:17:38.830  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 07:17:38.830  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 07:17:38.830  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 07:17:38.830  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 07:17:38.831  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 07:17:38.831  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 07:17:39.440  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 07:17:39.444  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 07:17:39.449  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 07:17:39.457  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665145059455 with initial instances count: 4
2022-10-07 07:17:39.458  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 07:17:39.460  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665145059459, current=UP, previous=STARTING]
2022-10-07 07:17:39.463  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 07:17:39.530  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 07:17:39.559  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 07:17:39.733  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 07:17:39.733  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 07:17:39.738  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 07:17:39.738  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 07:17:39.738  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665145059733
2022-10-07 07:17:39.745  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 07:17:39.853  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 07:17:39.855  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 07:17:40.373  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 07:17:40.378  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 07:17:40.380  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:17:40.383  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:17:40.405  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 07:17:40.406  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:17:42.109  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 24.74 seconds (JVM running for 26.901)
2022-10-07 07:17:43.107  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=40, memberId='consumer-group_json-1-1ffe8bbf-b343-49fe-a77e-9420b169e390', protocol='range'}
2022-10-07 07:17:43.575  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=40, memberId='consumer-group_json-1-1ffe8bbf-b343-49fe-a77e-9420b169e390', protocol='range'}
2022-10-07 07:17:43.583  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 07:17:43.588  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 07:17:43.611  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 07:17:43.615  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 07:19:02.808  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] o.m.d.connection                         : Opened connection [connectionId{localValue:3, serverValue:123}] to localhost:27017
2022-10-07 07:19:47.275  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] o.m.d.connection                         : Opened connection [connectionId{localValue:4, serverValue:124}] to localhost:27017
2022-10-07 07:19:55.180 ERROR LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] a.w.r.e.AbstractErrorWebExceptionHandler : [75fd48d1-1]  500 Server Error for HTTP POST "/operation/accountClient/assignPrincipalAccount"
java.lang.ClassCastException: Cannot cast java.lang.IndexOutOfBoundsException to org.springframework.web.bind.support.WebExchangeBindException
	at java.base/java.lang.Class.cast(Class.java:3605)
	Suppressed: java.lang.IndexOutOfBoundsException: Source emitted more than one item
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:712)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:588)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:971)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1798)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: The stacktrace has been enhanced by Reactor, refer to additional information below: 
Error has been observed at the following site(s):
	*__checkpoint  Handler nttdata.grupouno.com.operations.controllers.AccountClientController#assignPrincipalAccount(Mono) [DispatcherHandler]
	*__checkpoint  org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain]
	*__checkpoint  HTTP POST "/operation/accountClient/assignPrincipalAccount" [ExceptionHandlingWebHandler]
Original Stack Trace:
		at java.base/java.lang.Class.cast(Class.java:3605)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:113)
		at reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2398)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onSubscribe(MonoFlatMap.java:110)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)
		at reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:103)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.FluxMap$MapSubscriber.onError(FluxMap.java:134)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onError(MonoSingle.java:150)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:712)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:588)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:971)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1798)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 07:21:45.328  INFO LAPTOP-LTI5PG0G --- [freshExecutor-0] o.a.h.i.e.RetryExec                      : I/O exception (java.net.SocketException) caught when processing request to {}->http://localhost:8761: Software caused connection abort: recv failed
2022-10-07 07:22:02.886  INFO LAPTOP-LTI5PG0G --- [freshExecutor-0] o.a.h.i.e.RetryExec                      : Retrying request to {}->http://localhost:8761
2022-10-07 07:22:02.891  WARN LAPTOP-LTI5PG0G --- [scoveryClient-1] c.n.d.TimedSupervisorTask                : task supervisor timed out
java.util.concurrent.TimeoutException
	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
	at com.netflix.discovery.TimedSupervisorTask.run(TimedSupervisorTask.java:68)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 07:22:02.897  WARN LAPTOP-LTI5PG0G --- [scoveryClient-0] c.n.d.TimedSupervisorTask                : task supervisor timed out
java.util.concurrent.TimeoutException
	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
	at com.netflix.discovery.TimedSupervisorTask.run(TimedSupervisorTask.java:68)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 07:22:29.441  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-10-07 07:22:29.445  INFO LAPTOP-LTI5PG0G --- [tbeatExecutor-0] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/} exception=I/O error on PUT request for "http://localhost:8761/eureka/apps/OPERATION-SERVICES/host.docker.internal:operation-services:8010": Software caused connection abort: recv failed; nested exception is java.net.SocketException: Software caused connection abort: recv failed stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on PUT request for "http://localhost:8761/eureka/apps/OPERATION-SERVICES/host.docker.internal:operation-services:8010": Software caused connection abort: recv failed; nested exception is java.net.SocketException: Software caused connection abort: recv failed
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:785)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:711)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:602)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.sendHeartBeat(RestTemplateEurekaHttpClient.java:99)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:91)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:893)
	at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1457)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketException: Software caused connection abort: recv failed
	at java.base/java.net.SocketInputStream.socketRead0(Native Method)
	at java.base/java.net.SocketInputStream.socketRead(SocketInputStream.java:115)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:168)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at org.apache.http.impl.io.SessionInputBufferImpl.streamRead(SessionInputBufferImpl.java:137)
	at org.apache.http.impl.io.SessionInputBufferImpl.fillBuffer(SessionInputBufferImpl.java:153)
	at org.apache.http.impl.io.SessionInputBufferImpl.readLine(SessionInputBufferImpl.java:280)
	at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:138)
	at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:56)
	at org.apache.http.impl.io.AbstractMessageParser.parse(AbstractMessageParser.java:259)
	at org.apache.http.impl.DefaultBHttpClientConnection.receiveResponseHeader(DefaultBHttpClientConnection.java:163)
	at org.apache.http.impl.conn.CPoolProxy.receiveResponseHeader(CPoolProxy.java:157)
	at org.apache.http.protocol.HttpRequestExecutor.doReceiveResponse(HttpRequestExecutor.java:273)
	at org.apache.http.protocol.HttpRequestExecutor.execute(HttpRequestExecutor.java:125)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:272)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:87)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:776)
	... 20 more

2022-10-07 07:22:29.446  WARN LAPTOP-LTI5PG0G --- [tbeatExecutor-0] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with message: I/O error on PUT request for "http://localhost:8761/eureka/apps/OPERATION-SERVICES/host.docker.internal:operation-services:8010": Software caused connection abort: recv failed; nested exception is java.net.SocketException: Software caused connection abort: recv failed
2022-10-07 07:22:29.442  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Requesting disconnect from last known coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:22:29.451  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Client requested disconnect from node 2147483647
2022-10-07 07:24:11.695  INFO LAPTOP-LTI5PG0G --- [tbeatExecutor-0] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution succeeded on retry #1
2022-10-07 07:24:16.192  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 07:24:16.196  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:24:16.190 ERROR LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] a.w.r.e.AbstractErrorWebExceptionHandler : [75fd48d1-2]  500 Server Error for HTTP POST "/operation/accountClient/assignPrincipalAccount"
java.lang.ClassCastException: Cannot cast java.lang.IndexOutOfBoundsException to org.springframework.web.bind.support.WebExchangeBindException
	at java.base/java.lang.Class.cast(Class.java:3605)
	Suppressed: java.lang.IndexOutOfBoundsException: Source emitted more than one item
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:712)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:588)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:971)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1798)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: The stacktrace has been enhanced by Reactor, refer to additional information below: 
Error has been observed at the following site(s):
	*__checkpoint  Handler nttdata.grupouno.com.operations.controllers.AccountClientController#assignPrincipalAccount(Mono) [DispatcherHandler]
	*__checkpoint  org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain]
	*__checkpoint  HTTP POST "/operation/accountClient/assignPrincipalAccount" [ExceptionHandlingWebHandler]
Original Stack Trace:
		at java.base/java.lang.Class.cast(Class.java:3605)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:113)
		at reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2398)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onSubscribe(MonoFlatMap.java:110)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)
		at reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:103)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.FluxMap$MapSubscriber.onError(FluxMap.java:134)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onError(MonoSingle.java:150)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:712)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:588)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:971)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1798)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 07:24:16.201  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:24:16.216  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Attempt to heartbeat with Generation{generationId=40, memberId='consumer-group_json-1-1ffe8bbf-b343-49fe-a77e-9420b169e390', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-10-07 07:24:16.217  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-10-07 07:24:16.217  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-10-07 07:24:16.218  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-10-07 07:24:16.218  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Lost previously assigned partitions Kafka_target-0
2022-10-07 07:24:16.221  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions lost: [Kafka_target-0]
2022-10-07 07:24:16.224  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 07:24:16.226  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:24:16.233  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 07:24:16.234  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:24:17.131  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=42, memberId='consumer-group_json-1-3d5f3371-2acd-4a35-863b-8937cebe7c19', protocol='range'}
2022-10-07 07:24:17.484  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=42, memberId='consumer-group_json-1-3d5f3371-2acd-4a35-863b-8937cebe7c19', protocol='range'}
2022-10-07 07:24:17.485  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 07:24:17.486  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 07:24:17.493  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 07:24:17.494  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 07:25:40.675  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Disconnecting from node 2147483647 due to request timeout.
2022-10-07 07:25:51.420  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cancelled in-flight HEARTBEAT request with correlation id 358 due to node 2147483647 being disconnected (elapsed time since creation: 55919ms, elapsed time since send: 55918ms, request timeout: 30000ms)
2022-10-07 07:25:51.435  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-10-07 07:25:51.444  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Requesting disconnect from last known coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:25:51.437 ERROR LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] a.w.r.e.AbstractErrorWebExceptionHandler : [75fd48d1-3]  500 Server Error for HTTP POST "/operation/accountClient/assignPrincipalAccount"
java.lang.ClassCastException: Cannot cast java.lang.IndexOutOfBoundsException to org.springframework.web.bind.support.WebExchangeBindException
	at java.base/java.lang.Class.cast(Class.java:3605)
	Suppressed: java.lang.IndexOutOfBoundsException: Source emitted more than one item
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:712)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:588)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:971)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1798)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: The stacktrace has been enhanced by Reactor, refer to additional information below: 
Error has been observed at the following site(s):
	*__checkpoint  Handler nttdata.grupouno.com.operations.controllers.AccountClientController#assignPrincipalAccount(Mono) [DispatcherHandler]
	*__checkpoint  org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain]
	*__checkpoint  HTTP POST "/operation/accountClient/assignPrincipalAccount" [ExceptionHandlingWebHandler]
Original Stack Trace:
		at java.base/java.lang.Class.cast(Class.java:3605)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:113)
		at reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2398)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onSubscribe(MonoFlatMap.java:110)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)
		at reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:103)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.FluxMap$MapSubscriber.onError(FluxMap.java:134)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onError(MonoSingle.java:150)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:712)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:588)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:971)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1798)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 07:25:51.948  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:25:51.951  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:25:51.953  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:25:51.958  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Attempt to heartbeat with Generation{generationId=42, memberId='consumer-group_json-1-3d5f3371-2acd-4a35-863b-8937cebe7c19', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-10-07 07:25:51.958  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-10-07 07:25:51.958  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-10-07 07:25:51.959  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-10-07 07:25:51.959  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Lost previously assigned partitions Kafka_target-0
2022-10-07 07:25:51.959  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions lost: [Kafka_target-0]
2022-10-07 07:25:51.960  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 07:25:51.960  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:25:51.964  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 07:25:51.965  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:25:53.420  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=44, memberId='consumer-group_json-1-9c33d700-70b6-4d71-9d27-351dee39453d', protocol='range'}
2022-10-07 07:25:53.514  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=44, memberId='consumer-group_json-1-9c33d700-70b6-4d71-9d27-351dee39453d', protocol='range'}
2022-10-07 07:25:53.515  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 07:25:53.516  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 07:25:53.522  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 07:25:53.523  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 07:26:40.825  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Node -1 disconnected.
2022-10-07 07:29:16.218  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 07:34:16.227  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 07:35:57.588  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application OPERATION-SERVICES with eureka with status DOWN
2022-10-07 07:35:57.589  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665146157589, current=DOWN, previous=UP]
2022-10-07 07:35:57.589  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 07:35:57.603  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 07:35:57.607  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Revoke previously assigned partitions Kafka_target-0
2022-10-07 07:35:57.608  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 07:35:57.608  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Member consumer-group_json-1-9c33d700-70b6-4d71-9d27-351dee39453d sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2022-10-07 07:35:57.610  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 07:35:57.610  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 07:35:57.611  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Unsubscribed all topics or patterns and assigned partitions
2022-10-07 07:35:57.612  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 07:35:57.613  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 07:35:57.620  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics scheduler closed
2022-10-07 07:35:57.620  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-10-07 07:35:57.621  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics reporters closed
2022-10-07 07:35:57.628  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.u.AppInfoParser                  : App info kafka.consumer for consumer-group_json-1 unregistered
2022-10-07 07:35:57.629  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: Consumer stopped
2022-10-07 07:36:01.856  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Shutting down DiscoveryClient ...
2022-10-07 07:36:04.866  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Unregistering ...
2022-10-07 07:36:04.880  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - deregister  status: 200
2022-10-07 07:36:04.888  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Completed shut down of DiscoveryClient
2022-10-07 07:36:14.375  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 07:36:16.644  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 07:36:21.265  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 07:36:21.267  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 07:36:21.279  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 07:36:23.148  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 07:36:23.470  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 311 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 07:36:24.079  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 07:36:24.295  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:36:24.299  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:36:24.302  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:36:26.622  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@65d90b7f, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@2a42019a], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@6fc0e448]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@60194904], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 07:36:26.873  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 07:36:27.359  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 07:36:29.228  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:125}] to localhost:27017
2022-10-07 07:36:29.228  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:126}] to localhost:27017
2022-10-07 07:36:29.230  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=141049500}
2022-10-07 07:36:32.587  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 07:36:34.265  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 07:36:34.400  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 07:36:34.526  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 07:36:34.627  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 07:36:34.637  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 07:36:34.696  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 07:36:34.697  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 07:36:34.697  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 07:36:34.697  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 07:36:34.697  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 07:36:34.698  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 07:36:34.698  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 07:36:35.189  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 07:36:35.192  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 07:36:35.196  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 07:36:35.203  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665146195202 with initial instances count: 4
2022-10-07 07:36:35.205  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 07:36:35.206  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665146195206, current=UP, previous=STARTING]
2022-10-07 07:36:35.209  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 07:36:35.274  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 07:36:35.295  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 07:36:35.476  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 07:36:35.476  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 07:36:35.481  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 07:36:35.482  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 07:36:35.482  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665146195477
2022-10-07 07:36:35.490  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 07:36:35.611  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 07:36:35.613  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 07:36:36.200  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 07:36:36.205  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 07:36:36.207  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:36:36.211  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:36:36.233  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 07:36:36.234  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:36:37.098  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=46, memberId='consumer-group_json-1-cb4d0201-693d-4915-ad32-c7469fb1107d', protocol='range'}
2022-10-07 07:36:37.412  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=46, memberId='consumer-group_json-1-cb4d0201-693d-4915-ad32-c7469fb1107d', protocol='range'}
2022-10-07 07:36:37.418  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 07:36:37.423  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 07:36:37.444  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 07:36:37.446  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 07:36:37.848  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 25.785 seconds (JVM running for 27.927)
2022-10-07 07:37:16.913  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] o.m.d.connection                         : Opened connection [connectionId{localValue:3, serverValue:127}] to localhost:27017
2022-10-07 07:37:17.239  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] o.m.d.connection                         : Opened connection [connectionId{localValue:4, serverValue:128}] to localhost:27017
2022-10-07 07:37:17.297 ERROR LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] a.w.r.e.AbstractErrorWebExceptionHandler : [7edeb6d1-1]  500 Server Error for HTTP POST "/operation/accountClient/assignPrincipalAccount"
java.lang.ClassCastException: Cannot cast java.lang.IndexOutOfBoundsException to org.springframework.web.bind.support.WebExchangeBindException
	at java.base/java.lang.Class.cast(Class.java:3605)
	Suppressed: java.lang.IndexOutOfBoundsException: Source emitted more than one item
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:712)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:588)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:971)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1798)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: The stacktrace has been enhanced by Reactor, refer to additional information below: 
Error has been observed at the following site(s):
	*__checkpoint  Handler nttdata.grupouno.com.operations.controllers.AccountClientController#assignPrincipalAccount(Mono) [DispatcherHandler]
	*__checkpoint  org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain]
	*__checkpoint  HTTP POST "/operation/accountClient/assignPrincipalAccount" [ExceptionHandlingWebHandler]
Original Stack Trace:
		at java.base/java.lang.Class.cast(Class.java:3605)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:113)
		at reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2398)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onSubscribe(MonoFlatMap.java:110)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)
		at reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:103)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.FluxMap$MapSubscriber.onError(FluxMap.java:134)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onError(MonoSingle.java:150)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:712)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:588)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:971)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1798)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 07:39:19.565  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application OPERATION-SERVICES with eureka with status DOWN
2022-10-07 07:39:19.566  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665146359566, current=DOWN, previous=UP]
2022-10-07 07:39:19.567  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 07:39:19.581  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Revoke previously assigned partitions Kafka_target-0
2022-10-07 07:39:19.582  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 07:39:19.583  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Member consumer-group_json-1-cb4d0201-693d-4915-ad32-c7469fb1107d sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2022-10-07 07:39:19.584  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 07:39:19.584  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 07:39:19.584  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Unsubscribed all topics or patterns and assigned partitions
2022-10-07 07:39:19.585  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 07:39:19.586  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 07:39:19.588  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 07:39:19.590  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics scheduler closed
2022-10-07 07:39:19.591  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-10-07 07:39:19.591  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics reporters closed
2022-10-07 07:39:19.599  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.u.AppInfoParser                  : App info kafka.consumer for consumer-group_json-1 unregistered
2022-10-07 07:39:19.601  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: Consumer stopped
2022-10-07 07:39:23.827  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Shutting down DiscoveryClient ...
2022-10-07 07:39:26.836  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Unregistering ...
2022-10-07 07:39:26.851  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - deregister  status: 200
2022-10-07 07:39:26.860  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Completed shut down of DiscoveryClient
2022-10-07 07:39:37.285  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 07:39:39.325  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 07:39:44.349  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 07:39:44.352  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 07:39:44.366  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 07:39:46.322  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 07:39:46.637  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 305 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 07:39:47.349  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 07:39:47.550  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:39:47.553  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:39:47.557  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:39:50.040  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@2493eec6, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@42d174ad], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@4ec0229c]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@173a5fad], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 07:39:50.285  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 07:39:50.726  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 07:39:52.681  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:130}] to localhost:27017
2022-10-07 07:39:52.681  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:129}] to localhost:27017
2022-10-07 07:39:52.683  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=168647400}
2022-10-07 07:39:56.153  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 07:39:57.984  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 07:39:58.156  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 07:39:58.301  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 07:39:58.416  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 07:39:58.428  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 07:39:58.494  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 07:39:58.494  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 07:39:58.494  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 07:39:58.494  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 07:39:58.495  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 07:39:58.495  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 07:39:58.495  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 07:39:59.154  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 07:39:59.159  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 07:39:59.164  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 07:39:59.172  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665146399171 with initial instances count: 4
2022-10-07 07:39:59.174  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 07:39:59.175  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665146399175, current=UP, previous=STARTING]
2022-10-07 07:39:59.179  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 07:39:59.270  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 07:39:59.295  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 07:39:59.506  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 07:39:59.506  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 07:39:59.508  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 07:39:59.509  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 07:39:59.509  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665146399506
2022-10-07 07:39:59.514  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 07:39:59.640  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 07:39:59.644  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 07:40:00.188  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 07:40:00.194  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 07:40:00.197  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:40:00.202  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:40:00.228  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 07:40:00.228  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:40:01.723  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=48, memberId='consumer-group_json-1-eb3c41ec-1b41-4acb-ac49-9ec65e43e085', protocol='range'}
2022-10-07 07:40:01.860  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 26.955 seconds (JVM running for 29.056)
2022-10-07 07:40:02.101  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=48, memberId='consumer-group_json-1-eb3c41ec-1b41-4acb-ac49-9ec65e43e085', protocol='range'}
2022-10-07 07:40:02.107  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 07:40:02.111  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 07:40:02.132  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 07:40:02.134  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 07:40:26.672  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] o.m.d.connection                         : Opened connection [connectionId{localValue:3, serverValue:131}] to localhost:27017
2022-10-07 07:41:29.510  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] o.m.d.connection                         : Opened connection [connectionId{localValue:4, serverValue:132}] to localhost:27017
2022-10-07 07:41:29.525  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-10-07 07:41:29.526  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Requesting disconnect from last known coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:41:29.531  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Client requested disconnect from node 2147483647
2022-10-07 07:42:41.290  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:42:41.292  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-10-07 07:42:41.278  WARN LAPTOP-LTI5PG0G --- [scoveryClient-0] c.n.d.TimedSupervisorTask                : task supervisor timed out
java.util.concurrent.TimeoutException
	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
	at com.netflix.discovery.TimedSupervisorTask.run(TimedSupervisorTask.java:68)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 07:42:41.277  WARN LAPTOP-LTI5PG0G --- [scoveryClient-1] c.n.d.TimedSupervisorTask                : task supervisor timed out
java.util.concurrent.TimeoutException
	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
	at com.netflix.discovery.TimedSupervisorTask.run(TimedSupervisorTask.java:68)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 07:42:41.393 ERROR LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] a.w.r.e.AbstractErrorWebExceptionHandler : [393cfd10-1]  500 Server Error for HTTP POST "/operation/accountClient/assignPrincipalAccount"
java.lang.ClassCastException: Cannot cast java.lang.IndexOutOfBoundsException to org.springframework.web.bind.support.WebExchangeBindException
	at java.base/java.lang.Class.cast(Class.java:3605)
	Suppressed: java.lang.IndexOutOfBoundsException: Source emitted more than one item
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:712)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:588)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:971)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1798)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: The stacktrace has been enhanced by Reactor, refer to additional information below: 
Error has been observed at the following site(s):
	*__checkpoint  Handler nttdata.grupouno.com.operations.controllers.AccountClientController#assignPrincipalAccount(Mono) [DispatcherHandler]
	*__checkpoint  org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain]
	*__checkpoint  HTTP POST "/operation/accountClient/assignPrincipalAccount" [ExceptionHandlingWebHandler]
Original Stack Trace:
		at java.base/java.lang.Class.cast(Class.java:3605)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:113)
		at reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2398)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onSubscribe(MonoFlatMap.java:110)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)
		at reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:103)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onError(MonoSingle.java:150)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:712)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:588)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:971)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1798)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 07:42:41.814  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:42:41.824  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Attempt to heartbeat with Generation{generationId=48, memberId='consumer-group_json-1-eb3c41ec-1b41-4acb-ac49-9ec65e43e085', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-10-07 07:42:41.825  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-10-07 07:42:41.825  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-10-07 07:42:41.826  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-10-07 07:42:41.827  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Lost previously assigned partitions Kafka_target-0
2022-10-07 07:42:41.829  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions lost: [Kafka_target-0]
2022-10-07 07:42:41.830  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 07:42:41.831  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:42:41.836  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 07:42:41.837  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:42:44.204  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=50, memberId='consumer-group_json-1-4b478617-e08e-4e6b-b79e-c2b5a7240f94', protocol='range'}
2022-10-07 07:42:44.348  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=50, memberId='consumer-group_json-1-4b478617-e08e-4e6b-b79e-c2b5a7240f94', protocol='range'}
2022-10-07 07:42:44.349  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 07:42:44.350  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 07:42:44.357  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 07:42:44.358  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 07:47:29.544  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-10-07 07:47:29.544  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Requesting disconnect from last known coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:47:29.545  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Client requested disconnect from node 2147483647
2022-10-07 07:47:29.555  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 07:47:29.567  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:47:29.572  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-10-07 07:47:29.581 ERROR LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] a.w.r.e.AbstractErrorWebExceptionHandler : [393cfd10-2]  500 Server Error for HTTP POST "/operation/accountClient/assignPrincipalAccount"
java.lang.ClassCastException: Cannot cast java.lang.IndexOutOfBoundsException to org.springframework.web.bind.support.WebExchangeBindException
	at java.base/java.lang.Class.cast(Class.java:3605)
	Suppressed: java.lang.IndexOutOfBoundsException: Source emitted more than one item
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:712)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:588)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:971)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1798)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: The stacktrace has been enhanced by Reactor, refer to additional information below: 
Error has been observed at the following site(s):
	*__checkpoint  Handler nttdata.grupouno.com.operations.controllers.AccountClientController#assignPrincipalAccount(Mono) [DispatcherHandler]
	*__checkpoint  org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain]
	*__checkpoint  HTTP POST "/operation/accountClient/assignPrincipalAccount" [ExceptionHandlingWebHandler]
Original Stack Trace:
		at java.base/java.lang.Class.cast(Class.java:3605)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:113)
		at reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2398)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onSubscribe(MonoFlatMap.java:110)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)
		at reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:103)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onError(MonoSingle.java:150)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:712)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:588)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:971)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1798)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 07:47:29.665  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application OPERATION-SERVICES with eureka with status DOWN
2022-10-07 07:47:29.667  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665146849667, current=DOWN, previous=UP]
2022-10-07 07:47:29.668  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 07:47:29.680  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 07:47:29.694  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Revoke previously assigned partitions Kafka_target-0
2022-10-07 07:47:29.695  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 07:47:29.696  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 07:47:29.696  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 07:47:29.696  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Unsubscribed all topics or patterns and assigned partitions
2022-10-07 07:47:29.697  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 07:47:29.698  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 07:47:29.699  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics scheduler closed
2022-10-07 07:47:29.700  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-10-07 07:47:29.700  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics reporters closed
2022-10-07 07:47:29.709  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.u.AppInfoParser                  : App info kafka.consumer for consumer-group_json-1 unregistered
2022-10-07 07:47:29.710  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: Consumer stopped
2022-10-07 07:47:33.956  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Shutting down DiscoveryClient ...
2022-10-07 07:47:36.968  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Unregistering ...
2022-10-07 07:47:36.986  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - deregister  status: 200
2022-10-07 07:47:36.997  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Completed shut down of DiscoveryClient
2022-10-07 07:47:57.109  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 07:47:59.119  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 07:48:03.382  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 07:48:03.386  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 07:48:03.402  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 07:48:05.132  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 07:48:05.456  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 314 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 07:48:06.153  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 07:48:06.372  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:48:06.375  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:48:06.379  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:48:08.753  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@4ec0229c, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@173a5fad], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@2ce47652]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@65d90b7f], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 07:48:09.008  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 07:48:09.468  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 07:48:11.335  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:134}] to localhost:27017
2022-10-07 07:48:11.335  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:133}] to localhost:27017
2022-10-07 07:48:11.337  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=143690600}
2022-10-07 07:48:14.344  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 07:48:16.080  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 07:48:16.231  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 07:48:16.361  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 07:48:16.463  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 07:48:16.470  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 07:48:16.516  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 07:48:16.516  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 07:48:16.516  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 07:48:16.517  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 07:48:16.517  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 07:48:16.517  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 07:48:16.517  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 07:48:17.087  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 07:48:17.091  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 07:48:17.094  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 07:48:17.102  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665146897101 with initial instances count: 4
2022-10-07 07:48:17.104  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 07:48:17.105  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665146897105, current=UP, previous=STARTING]
2022-10-07 07:48:17.108  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 07:48:17.174  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 07:48:17.202  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 07:48:17.412  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 07:48:17.412  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 07:48:17.417  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 07:48:17.417  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 07:48:17.417  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665146897412
2022-10-07 07:48:17.424  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 07:48:17.529  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 07:48:17.530  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 07:48:18.009  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 07:48:18.013  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 07:48:18.014  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:48:18.018  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:48:18.037  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 07:48:18.038  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:48:18.131  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=52, memberId='consumer-group_json-1-b779dd63-73f6-4940-8112-279e01a457cd', protocol='range'}
2022-10-07 07:48:18.583  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=52, memberId='consumer-group_json-1-b779dd63-73f6-4940-8112-279e01a457cd', protocol='range'}
2022-10-07 07:48:18.588  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 07:48:18.593  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 07:48:18.611  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 07:48:18.613  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 07:48:19.824  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 24.981 seconds (JVM running for 27.134)
2022-10-07 07:48:20.040  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application OPERATION-SERVICES with eureka with status DOWN
2022-10-07 07:48:20.041  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665146900041, current=DOWN, previous=UP]
2022-10-07 07:48:20.042  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 07:48:20.053  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 07:48:20.057  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Revoke previously assigned partitions Kafka_target-0
2022-10-07 07:48:20.058  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 07:48:20.060  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Member consumer-group_json-1-b779dd63-73f6-4940-8112-279e01a457cd sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2022-10-07 07:48:20.062  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 07:48:20.062  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 07:48:20.063  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Unsubscribed all topics or patterns and assigned partitions
2022-10-07 07:48:20.064  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 07:48:20.064  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 07:48:20.070  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics scheduler closed
2022-10-07 07:48:20.071  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-10-07 07:48:20.071  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics reporters closed
2022-10-07 07:48:20.079  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.u.AppInfoParser                  : App info kafka.consumer for consumer-group_json-1 unregistered
2022-10-07 07:48:20.081  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: Consumer stopped
2022-10-07 07:48:24.269  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Shutting down DiscoveryClient ...
2022-10-07 07:48:27.276  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Unregistering ...
2022-10-07 07:48:27.290  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - deregister  status: 200
2022-10-07 07:48:27.298  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Completed shut down of DiscoveryClient
2022-10-07 07:48:58.473  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 07:49:00.477  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 07:49:04.805  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 07:49:04.808  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 07:49:04.822  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 07:49:06.796  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 07:49:07.114  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 307 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 07:49:07.824  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 07:49:08.034  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:49:08.037  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:49:08.041  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:49:10.400  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@2ce47652, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@65d90b7f], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@2a42019a]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@6fc0e448], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 07:49:10.649  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 07:49:11.087  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 07:49:12.981  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:136}] to localhost:27017
2022-10-07 07:49:12.981  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:135}] to localhost:27017
2022-10-07 07:49:12.983  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=143751000}
2022-10-07 07:49:16.151  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 07:49:17.974  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 07:49:18.149  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 07:49:18.275  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 07:49:18.387  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 07:49:18.399  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 07:49:18.465  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 07:49:18.466  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 07:49:18.466  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 07:49:18.466  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 07:49:18.466  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 07:49:18.467  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 07:49:18.467  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 07:49:19.110  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 07:49:19.115  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 07:49:19.121  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 07:49:19.131  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665146959129 with initial instances count: 4
2022-10-07 07:49:19.134  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 07:49:19.135  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665146959135, current=UP, previous=STARTING]
2022-10-07 07:49:19.139  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 07:49:19.213  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 07:49:19.231  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 07:49:19.360  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 07:49:19.361  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 07:49:19.363  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 07:49:19.364  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 07:49:19.364  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665146959361
2022-10-07 07:49:19.368  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 07:49:19.484  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 07:49:19.486  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 07:49:19.924  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 07:49:19.928  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 07:49:19.930  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:49:19.933  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:49:19.953  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 07:49:19.953  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:49:21.343  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=54, memberId='consumer-group_json-1-c8d2be08-4e11-49ad-902d-98250c2ff539', protocol='range'}
2022-10-07 07:49:21.603  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=54, memberId='consumer-group_json-1-c8d2be08-4e11-49ad-902d-98250c2ff539', protocol='range'}
2022-10-07 07:49:21.610  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 07:49:21.614  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 07:49:21.632  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 07:49:21.634  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 07:49:21.737  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 25.473 seconds (JVM running for 27.639)
2022-10-07 07:49:33.221  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] o.m.d.connection                         : Opened connection [connectionId{localValue:3, serverValue:137}] to localhost:27017
2022-10-07 07:49:33.547  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] o.m.d.connection                         : Opened connection [connectionId{localValue:4, serverValue:138}] to localhost:27017
2022-10-07 07:49:33.599 ERROR LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] a.w.r.e.AbstractErrorWebExceptionHandler : [b1ba9e6a-1]  500 Server Error for HTTP POST "/operation/accountClient/assignPrincipalAccount"
java.lang.ClassCastException: Cannot cast java.lang.IndexOutOfBoundsException to org.springframework.web.bind.support.WebExchangeBindException
	at java.base/java.lang.Class.cast(Class.java:3605)
	Suppressed: java.lang.IndexOutOfBoundsException: Source emitted more than one item
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.tryEmit(FluxFlatMap.java:543)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:984)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: The stacktrace has been enhanced by Reactor, refer to additional information below: 
Error has been observed at the following site(s):
	*__checkpoint  Handler nttdata.grupouno.com.operations.controllers.AccountClientController#assignPrincipalAccount(Mono) [DispatcherHandler]
	*__checkpoint  org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain]
	*__checkpoint  HTTP POST "/operation/accountClient/assignPrincipalAccount" [ExceptionHandlingWebHandler]
Original Stack Trace:
		at java.base/java.lang.Class.cast(Class.java:3605)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:113)
		at reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2398)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onSubscribe(MonoFlatMap.java:110)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)
		at reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:103)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onError(MonoSingle.java:150)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.tryEmit(FluxFlatMap.java:543)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:984)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 07:49:47.283 ERROR LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] a.w.r.e.AbstractErrorWebExceptionHandler : [b1ba9e6a-2]  500 Server Error for HTTP POST "/operation/accountClient/assignPrincipalAccount"
java.lang.ClassCastException: Cannot cast java.lang.IndexOutOfBoundsException to org.springframework.web.bind.support.WebExchangeBindException
	at java.base/java.lang.Class.cast(Class.java:3605)
	Suppressed: java.lang.IndexOutOfBoundsException: Source emitted more than one item
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.tryEmit(FluxFlatMap.java:543)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:984)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: The stacktrace has been enhanced by Reactor, refer to additional information below: 
Error has been observed at the following site(s):
	*__checkpoint  Handler nttdata.grupouno.com.operations.controllers.AccountClientController#assignPrincipalAccount(Mono) [DispatcherHandler]
	*__checkpoint  org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain]
	*__checkpoint  HTTP POST "/operation/accountClient/assignPrincipalAccount" [ExceptionHandlingWebHandler]
Original Stack Trace:
		at java.base/java.lang.Class.cast(Class.java:3605)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:113)
		at reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2398)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onSubscribe(MonoFlatMap.java:110)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)
		at reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:103)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onError(MonoSingle.java:150)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.tryEmit(FluxFlatMap.java:543)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:984)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 07:53:09.853  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application OPERATION-SERVICES with eureka with status DOWN
2022-10-07 07:53:09.854  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665147189854, current=DOWN, previous=UP]
2022-10-07 07:53:09.854  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 07:53:09.871  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 07:53:09.873  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Revoke previously assigned partitions Kafka_target-0
2022-10-07 07:53:09.874  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 07:53:09.875  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Member consumer-group_json-1-c8d2be08-4e11-49ad-902d-98250c2ff539 sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2022-10-07 07:53:09.877  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 07:53:09.878  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 07:53:09.878  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Unsubscribed all topics or patterns and assigned partitions
2022-10-07 07:53:09.879  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 07:53:09.880  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 07:53:09.886  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics scheduler closed
2022-10-07 07:53:09.887  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-10-07 07:53:09.887  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics reporters closed
2022-10-07 07:53:09.894  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.u.AppInfoParser                  : App info kafka.consumer for consumer-group_json-1 unregistered
2022-10-07 07:53:09.896  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: Consumer stopped
2022-10-07 07:53:14.121  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Shutting down DiscoveryClient ...
2022-10-07 07:53:17.129  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Unregistering ...
2022-10-07 07:53:17.146  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - deregister  status: 200
2022-10-07 07:53:17.154  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Completed shut down of DiscoveryClient
2022-10-07 07:53:29.397  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 07:53:31.466  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 07:53:34.915  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 07:53:34.918  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 07:53:34.931  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 07:53:36.725  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 07:53:37.054  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 317 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 07:53:37.707  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 07:53:37.934  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:53:37.938  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:53:37.941  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 07:53:40.174  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@4ec0229c, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@173a5fad], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@2ce47652]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@65d90b7f], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 07:53:40.415  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 07:53:40.880  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 07:53:42.469  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:140}] to localhost:27017
2022-10-07 07:53:42.469  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:139}] to localhost:27017
2022-10-07 07:53:42.471  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=125889900}
2022-10-07 07:53:45.266  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 07:53:46.958  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 07:53:47.084  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 07:53:47.212  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 07:53:47.299  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 07:53:47.311  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 07:53:47.385  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 07:53:47.385  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 07:53:47.385  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 07:53:47.386  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 07:53:47.386  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 07:53:47.386  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 07:53:47.386  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 07:53:47.887  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 07:53:47.890  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 07:53:47.894  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 07:53:47.902  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665147227900 with initial instances count: 4
2022-10-07 07:53:47.903  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 07:53:47.904  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665147227904, current=UP, previous=STARTING]
2022-10-07 07:53:47.907  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 07:53:47.985  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 07:53:48.010  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 07:53:48.174  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 07:53:48.174  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 07:53:48.178  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 07:53:48.178  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 07:53:48.178  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665147228174
2022-10-07 07:53:48.184  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 07:53:48.301  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 07:53:48.303  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 07:53:48.922  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 07:53:48.926  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 07:53:48.928  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 07:53:48.932  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:53:48.954  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 07:53:48.955  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 07:53:49.080  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=56, memberId='consumer-group_json-1-8aac0305-c090-41be-a7c4-81cf6d9b7898', protocol='range'}
2022-10-07 07:53:49.145  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=56, memberId='consumer-group_json-1-8aac0305-c090-41be-a7c4-81cf6d9b7898', protocol='range'}
2022-10-07 07:53:49.152  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 07:53:49.159  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 07:53:49.179  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 07:53:49.180  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 07:53:50.562  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 23.321 seconds (JVM running for 25.465)
2022-10-07 07:53:59.484  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] o.m.d.connection                         : Opened connection [connectionId{localValue:3, serverValue:141}] to localhost:27017
2022-10-07 07:53:59.810  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] o.m.d.connection                         : Opened connection [connectionId{localValue:4, serverValue:142}] to localhost:27017
2022-10-07 07:58:47.405  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 08:02:49.053  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Node -1 disconnected.
2022-10-07 08:03:47.415  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 08:08:47.428  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 08:13:47.438  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 08:19:13.417  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 08:21:29.075 DEBUG LAPTOP-LTI5PG0G --- [ctor-http-nio-2] n.g.c.o.c.MovementDetailController       : idCartClient 4a2654ea-0495-4bb5-ae6d-bf46dbe7d845
2022-10-07 08:21:29.077 DEBUG LAPTOP-LTI5PG0G --- [ctor-http-nio-2] n.g.c.o.c.MovementDetailController       : amount operation 250.0
2022-10-07 08:21:29.077 DEBUG LAPTOP-LTI5PG0G --- [ctor-http-nio-2] n.g.c.o.c.MovementDetailController       : movementType D
2022-10-07 08:21:29.091 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] n.g.c.o.s.i.MasterAccountServices        : Cuenta 33333333333
2022-10-07 08:21:29.139 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] n.g.c.o.s.i.MasterAccountServices        : total movimientos 0
2022-10-07 08:21:29.186 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] n.g.c.o.s.i.MasterAccountServices        : Monto cuenta 420.5
2022-10-07 08:21:29.187 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] n.g.c.o.s.i.MasterAccountServices        : el saldo nuevo sera 670.5
2022-10-07 08:21:29.191 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] n.g.c.o.c.MovementDetailController       : exito
2022-10-07 08:23:12.741 DEBUG LAPTOP-LTI5PG0G --- [ctor-http-nio-2] n.g.c.o.c.MovementDetailController       : idCartClient 4a2654ea-0495-4bb5-ae6d-bf46dbe7d845
2022-10-07 08:23:12.742 DEBUG LAPTOP-LTI5PG0G --- [ctor-http-nio-2] n.g.c.o.c.MovementDetailController       : amount operation 300.0
2022-10-07 08:23:12.742 DEBUG LAPTOP-LTI5PG0G --- [ctor-http-nio-2] n.g.c.o.c.MovementDetailController       : movementType R
2022-10-07 08:23:12.751 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] n.g.c.o.s.i.MasterAccountServices        : Cuenta 1234567809
2022-10-07 08:23:12.765 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] n.g.c.o.s.i.MasterAccountServices        : total movimientos 0
2022-10-07 08:23:12.781 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] n.g.c.o.s.i.MasterAccountServices        : Monto cuenta 250.5
2022-10-07 08:23:12.782 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] n.g.c.o.c.MovementDetailController       : la cuenta 1234567809 no tiene saldo suficiente
2022-10-07 08:23:12.799 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] n.g.c.o.s.i.MasterAccountServices        : Cuenta 1234567809
2022-10-07 08:23:12.803 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] n.g.c.o.s.i.MasterAccountServices        : Cuenta 33333333333
2022-10-07 08:23:12.873 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] n.g.c.o.s.i.MasterAccountServices        : total movimientos 0
2022-10-07 08:23:12.874 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] n.g.c.o.s.i.MasterAccountServices        : total movimientos 1
2022-10-07 08:23:12.889 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] n.g.c.o.s.i.MasterAccountServices        : Monto cuenta 670.5
2022-10-07 08:23:12.890 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] n.g.c.o.s.i.MasterAccountServices        : el saldo nuevo sera 370.5
2022-10-07 08:23:12.891 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] n.g.c.o.s.i.MasterAccountServices        : Monto cuenta 250.5
2022-10-07 08:23:12.891 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] n.g.c.o.c.MovementDetailController       : la cuenta 1234567809 no tiene saldo suficiente
2022-10-07 08:23:12.892 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] n.g.c.o.c.MovementDetailController       : exito
2022-10-07 08:23:40.164 DEBUG LAPTOP-LTI5PG0G --- [ctor-http-nio-2] n.g.c.o.c.MovementDetailController       : idCartClient 4a2654ea-0495-4bb5-ae6d-bf46dbe7d845
2022-10-07 08:23:40.164 DEBUG LAPTOP-LTI5PG0G --- [ctor-http-nio-2] n.g.c.o.c.MovementDetailController       : amount operation 50.0
2022-10-07 08:23:40.164 DEBUG LAPTOP-LTI5PG0G --- [ctor-http-nio-2] n.g.c.o.c.MovementDetailController       : movementType R
2022-10-07 08:23:40.174 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] n.g.c.o.s.i.MasterAccountServices        : Cuenta 1234567809
2022-10-07 08:23:40.189 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] n.g.c.o.s.i.MasterAccountServices        : total movimientos 0
2022-10-07 08:23:40.212 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] n.g.c.o.s.i.MasterAccountServices        : Monto cuenta 250.5
2022-10-07 08:23:40.212 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] n.g.c.o.s.i.MasterAccountServices        : el saldo nuevo sera 200.5
2022-10-07 08:23:40.213 DEBUG LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] n.g.c.o.c.MovementDetailController       : exito
2022-10-07 08:24:13.419  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 08:29:13.428  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 08:34:13.434  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 08:39:13.441  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 08:44:13.452  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 08:49:13.463  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 08:54:13.478  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 08:59:13.487  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 09:04:13.502  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 09:07:06.850  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: group is already rebalancing
2022-10-07 09:07:06.855  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Revoke previously assigned partitions Kafka_target-0
2022-10-07 09:07:06.858  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 09:07:06.860  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 09:07:06.945  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=57, memberId='consumer-group_json-1-8aac0305-c090-41be-a7c4-81cf6d9b7898', protocol='range'}
2022-10-07 09:07:07.423  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=57, memberId='consumer-group_json-1-8aac0305-c090-41be-a7c4-81cf6d9b7898', protocol='range'}
2022-10-07 09:07:07.425  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 09:07:07.426  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 09:07:07.444  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 09:07:07.445  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 09:07:25.002  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: group is already rebalancing
2022-10-07 09:07:25.002  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Revoke previously assigned partitions Kafka_target-0
2022-10-07 09:07:25.003  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 09:07:25.003  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 09:07:25.017  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=58, memberId='consumer-group_json-1-8aac0305-c090-41be-a7c4-81cf6d9b7898', protocol='range'}
2022-10-07 09:07:25.306  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=58, memberId='consumer-group_json-1-8aac0305-c090-41be-a7c4-81cf6d9b7898', protocol='range'}
2022-10-07 09:07:25.306  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 09:07:25.307  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 09:07:25.316  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 09:07:25.317  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 09:09:13.512  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 09:11:22.682  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: group is already rebalancing
2022-10-07 09:11:22.683  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Revoke previously assigned partitions Kafka_target-0
2022-10-07 09:11:22.683  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 09:11:22.684  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 09:11:22.703  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=59, memberId='consumer-group_json-1-8aac0305-c090-41be-a7c4-81cf6d9b7898', protocol='range'}
2022-10-07 09:11:23.016  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=59, memberId='consumer-group_json-1-8aac0305-c090-41be-a7c4-81cf6d9b7898', protocol='range'}
2022-10-07 09:11:23.017  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 09:11:23.017  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 09:11:23.024  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 09:11:23.024  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 09:12:43.912  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: group is already rebalancing
2022-10-07 09:12:43.913  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Revoke previously assigned partitions Kafka_target-0
2022-10-07 09:12:43.913  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 09:12:43.914  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 09:12:43.918  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=60, memberId='consumer-group_json-1-8aac0305-c090-41be-a7c4-81cf6d9b7898', protocol='range'}
2022-10-07 09:12:44.081  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=60, memberId='consumer-group_json-1-8aac0305-c090-41be-a7c4-81cf6d9b7898', protocol='range'}
2022-10-07 09:12:44.081  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 09:12:44.082  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 09:12:44.085  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 09:12:44.086  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 09:14:13.519  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 09:15:32.426  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: group is already rebalancing
2022-10-07 09:15:32.426  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Revoke previously assigned partitions Kafka_target-0
2022-10-07 09:15:32.427  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 09:15:32.427  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 09:15:41.317  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=61, memberId='consumer-group_json-1-8aac0305-c090-41be-a7c4-81cf6d9b7898', protocol='range'}
2022-10-07 09:15:41.325  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=61, memberId='consumer-group_json-1-8aac0305-c090-41be-a7c4-81cf6d9b7898', protocol='range'}
2022-10-07 09:15:41.327  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 09:15:41.327  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 09:15:41.333  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 09:15:41.334  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 09:19:13.526  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 09:24:13.536  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 09:26:49.403  INFO LAPTOP-LTI5PG0G --- [freshExecutor-0] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/} exception=I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:785)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:711)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:602)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplicationsInternal(RestTemplateEurekaHttpClient.java:145)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getDelta(RestTemplateEurekaHttpClient.java:155)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:91)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.DiscoveryClient.getAndUpdateDelta(DiscoveryClient.java:1135)
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:1016)
	at com.netflix.discovery.DiscoveryClient.refreshRegistry(DiscoveryClient.java:1531)
	at com.netflix.discovery.DiscoveryClient$CacheRefreshThread.run(DiscoveryClient.java:1498)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:87)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:776)
	... 23 more
Caused by: java.net.ConnectException: Connection refused: connect
	at java.base/java.net.PlainSocketImpl.connect0(Native Method)
	at java.base/java.net.PlainSocketImpl.socketConnect(PlainSocketImpl.java:101)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:608)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 36 more

2022-10-07 09:26:49.403  INFO LAPTOP-LTI5PG0G --- [tbeatExecutor-0] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/} exception=I/O error on PUT request for "http://localhost:8761/eureka/apps/OPERATION-SERVICES/host.docker.internal:operation-services:8010": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on PUT request for "http://localhost:8761/eureka/apps/OPERATION-SERVICES/host.docker.internal:operation-services:8010": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:785)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:711)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:602)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.sendHeartBeat(RestTemplateEurekaHttpClient.java:99)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:91)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:893)
	at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1457)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:87)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:776)
	... 20 more
Caused by: java.net.ConnectException: Connection refused: connect
	at java.base/java.net.PlainSocketImpl.connect0(Native Method)
	at java.base/java.net.PlainSocketImpl.socketConnect(PlainSocketImpl.java:101)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:608)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 33 more

2022-10-07 09:26:49.412  WARN LAPTOP-LTI5PG0G --- [tbeatExecutor-0] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with message: I/O error on PUT request for "http://localhost:8761/eureka/apps/OPERATION-SERVICES/host.docker.internal:operation-services:8010": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
2022-10-07 09:26:49.412  WARN LAPTOP-LTI5PG0G --- [freshExecutor-0] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with message: I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
2022-10-07 09:26:49.435  INFO LAPTOP-LTI5PG0G --- [tbeatExecutor-0] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/}, exception=I/O error on PUT request for "http://localhost:8761/eureka/apps/OPERATION-SERVICES/host.docker.internal:operation-services:8010": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on PUT request for "http://localhost:8761/eureka/apps/OPERATION-SERVICES/host.docker.internal:operation-services:8010": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:785)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:711)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:602)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.sendHeartBeat(RestTemplateEurekaHttpClient.java:99)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:893)
	at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1457)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:87)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:776)
	... 21 more
Caused by: java.net.ConnectException: Connection refused: connect
	at java.base/java.net.PlainSocketImpl.connect0(Native Method)
	at java.base/java.net.PlainSocketImpl.socketConnect(PlainSocketImpl.java:101)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:608)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 34 more

2022-10-07 09:26:49.436  WARN LAPTOP-LTI5PG0G --- [tbeatExecutor-0] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with message: I/O error on PUT request for "http://localhost:8761/eureka/apps/OPERATION-SERVICES/host.docker.internal:operation-services:8010": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
2022-10-07 09:26:49.438 ERROR LAPTOP-LTI5PG0G --- [tbeatExecutor-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - was unable to send heartbeat!
com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:893)
	at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1457)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 09:26:49.440  INFO LAPTOP-LTI5PG0G --- [freshExecutor-0] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/}, exception=I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:785)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:711)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:602)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplicationsInternal(RestTemplateEurekaHttpClient.java:145)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getDelta(RestTemplateEurekaHttpClient.java:155)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.DiscoveryClient.getAndUpdateDelta(DiscoveryClient.java:1135)
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:1016)
	at com.netflix.discovery.DiscoveryClient.refreshRegistry(DiscoveryClient.java:1531)
	at com.netflix.discovery.DiscoveryClient$CacheRefreshThread.run(DiscoveryClient.java:1498)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:87)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:776)
	... 24 more
Caused by: java.net.ConnectException: Connection refused: connect
	at java.base/java.net.PlainSocketImpl.connect0(Native Method)
	at java.base/java.net.PlainSocketImpl.socketConnect(PlainSocketImpl.java:101)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:608)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 37 more

2022-10-07 09:26:49.441  WARN LAPTOP-LTI5PG0G --- [freshExecutor-0] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with message: I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
2022-10-07 09:26:49.442  INFO LAPTOP-LTI5PG0G --- [freshExecutor-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - was unable to refresh its cache! This periodic background refresh will be retried in 30 seconds. status = Cannot execute request on any known server stacktrace = com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.DiscoveryClient.getAndUpdateDelta(DiscoveryClient.java:1135)
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:1016)
	at com.netflix.discovery.DiscoveryClient.refreshRegistry(DiscoveryClient.java:1531)
	at com.netflix.discovery.DiscoveryClient$CacheRefreshThread.run(DiscoveryClient.java:1498)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)

2022-10-07 09:27:05.507  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application OPERATION-SERVICES with eureka with status DOWN
2022-10-07 09:27:05.508  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665152825508, current=DOWN, previous=UP]
2022-10-07 09:27:05.509  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 09:27:05.538  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/}, exception=I/O error on POST request for "http://localhost:8761/eureka/apps/OPERATION-SERVICES": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on POST request for "http://localhost:8761/eureka/apps/OPERATION-SERVICES": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:785)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:711)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:602)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.register(RestTemplateEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:876)
	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:121)
	at com.netflix.discovery.InstanceInfoReplicator$1.run(InstanceInfoReplicator.java:101)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:87)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:776)
	... 23 more
Caused by: java.net.ConnectException: Connection refused: connect
	at java.base/java.net.PlainSocketImpl.connect0(Native Method)
	at java.base/java.net.PlainSocketImpl.socketConnect(PlainSocketImpl.java:101)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:608)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 36 more

2022-10-07 09:27:05.539  WARN LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with message: I/O error on POST request for "http://localhost:8761/eureka/apps/OPERATION-SERVICES": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
2022-10-07 09:27:05.539  WARN LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration failed Cannot execute request on any known server
com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:876)
	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:121)
	at com.netflix.discovery.InstanceInfoReplicator$1.run(InstanceInfoReplicator.java:101)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 09:27:05.540  WARN LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.InstanceInfoReplicator             : There was a problem with the instance info replicator
com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:876)
	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:121)
	at com.netflix.discovery.InstanceInfoReplicator$1.run(InstanceInfoReplicator.java:101)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:264)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 09:27:05.608  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Revoke previously assigned partitions Kafka_target-0
2022-10-07 09:27:05.608  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 09:27:05.609  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Member consumer-group_json-1-8aac0305-c090-41be-a7c4-81cf6d9b7898 sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2022-10-07 09:27:05.611  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 09:27:05.611  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 09:27:05.611  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Unsubscribed all topics or patterns and assigned partitions
2022-10-07 09:27:05.614  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: consumer pro-actively leaving the group
2022-10-07 09:27:05.614  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: consumer pro-actively leaving the group
2022-10-07 09:27:05.620  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics scheduler closed
2022-10-07 09:27:05.620  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-10-07 09:27:05.621  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.m.Metrics                        : Metrics reporters closed
2022-10-07 09:27:05.630  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.u.AppInfoParser                  : App info kafka.consumer for consumer-group_json-1 unregistered
2022-10-07 09:27:05.632  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: Consumer stopped
2022-10-07 09:27:09.956  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Shutting down DiscoveryClient ...
2022-10-07 09:27:12.968  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Unregistering ...
2022-10-07 09:27:12.984  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/}, exception=I/O error on DELETE request for "http://localhost:8761/eureka/apps/OPERATION-SERVICES/host.docker.internal:operation-services:8010": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on DELETE request for "http://localhost:8761/eureka/apps/OPERATION-SERVICES/host.docker.internal:operation-services:8010": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:785)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:711)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:602)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.cancel(RestTemplateEurekaHttpClient.java:87)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$2.execute(EurekaHttpClientDecorator.java:74)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.cancel(EurekaHttpClientDecorator.java:71)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$2.execute(EurekaHttpClientDecorator.java:74)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.cancel(EurekaHttpClientDecorator.java:71)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$2.execute(EurekaHttpClientDecorator.java:74)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.cancel(EurekaHttpClientDecorator.java:71)
	at com.netflix.discovery.DiscoveryClient.unregister(DiscoveryClient.java:972)
	at com.netflix.discovery.DiscoveryClient.shutdown(DiscoveryClient.java:948)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389)
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeDestroyMethods(InitDestroyAnnotationBeanPostProcessor.java:347)
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeDestruction(InitDestroyAnnotationBeanPostProcessor.java:177)
	at org.springframework.beans.factory.support.DisposableBeanAdapter.destroy(DisposableBeanAdapter.java:197)
	at org.springframework.beans.factory.support.DisposableBeanAdapter.run(DisposableBeanAdapter.java:190)
	at org.springframework.cloud.context.scope.GenericScope$BeanLifecycleWrapper.destroy(GenericScope.java:390)
	at org.springframework.cloud.context.scope.GenericScope.destroy(GenericScope.java:136)
	at org.springframework.beans.factory.support.DisposableBeanAdapter.destroy(DisposableBeanAdapter.java:213)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:587)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:559)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:1163)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:520)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:1156)
	at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1106)
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1075)
	at org.springframework.boot.web.reactive.context.ReactiveWebServerApplicationContext.doClose(ReactiveWebServerApplicationContext.java:149)
	at org.springframework.context.support.AbstractApplicationContext.close(AbstractApplicationContext.java:1021)
	at org.springframework.boot.SpringApplicationShutdownHook.closeAndWait(SpringApplicationShutdownHook.java:145)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.boot.SpringApplicationShutdownHook.run(SpringApplicationShutdownHook.java:114)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:87)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:776)
	... 40 more
Caused by: java.net.ConnectException: Connection refused: connect
	at java.base/java.net.PlainSocketImpl.connect0(Native Method)
	at java.base/java.net.PlainSocketImpl.socketConnect(PlainSocketImpl.java:101)
	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412)
	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255)
	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.base/java.net.Socket.connect(Socket.java:608)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 53 more

2022-10-07 09:27:12.984  WARN LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with message: I/O error on DELETE request for "http://localhost:8761/eureka/apps/OPERATION-SERVICES/host.docker.internal:operation-services:8010": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
2022-10-07 09:27:12.985 ERROR LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - de-registration failedCannot execute request on any known server
com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.cancel(EurekaHttpClientDecorator.java:71)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$2.execute(EurekaHttpClientDecorator.java:74)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.cancel(EurekaHttpClientDecorator.java:71)
	at com.netflix.discovery.DiscoveryClient.unregister(DiscoveryClient.java:972)
	at com.netflix.discovery.DiscoveryClient.shutdown(DiscoveryClient.java:948)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389)
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeDestroyMethods(InitDestroyAnnotationBeanPostProcessor.java:347)
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeDestruction(InitDestroyAnnotationBeanPostProcessor.java:177)
	at org.springframework.beans.factory.support.DisposableBeanAdapter.destroy(DisposableBeanAdapter.java:197)
	at org.springframework.beans.factory.support.DisposableBeanAdapter.run(DisposableBeanAdapter.java:190)
	at org.springframework.cloud.context.scope.GenericScope$BeanLifecycleWrapper.destroy(GenericScope.java:390)
	at org.springframework.cloud.context.scope.GenericScope.destroy(GenericScope.java:136)
	at org.springframework.beans.factory.support.DisposableBeanAdapter.destroy(DisposableBeanAdapter.java:213)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:587)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:559)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:1163)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:520)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:1156)
	at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1106)
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1075)
	at org.springframework.boot.web.reactive.context.ReactiveWebServerApplicationContext.doClose(ReactiveWebServerApplicationContext.java:149)
	at org.springframework.context.support.AbstractApplicationContext.close(AbstractApplicationContext.java:1021)
	at org.springframework.boot.SpringApplicationShutdownHook.closeAndWait(SpringApplicationShutdownHook.java:145)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.boot.SpringApplicationShutdownHook.run(SpringApplicationShutdownHook.java:114)
	at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 09:27:12.995  INFO LAPTOP-LTI5PG0G --- [ionShutdownHook] c.n.d.DiscoveryClient                    : Completed shut down of DiscoveryClient
